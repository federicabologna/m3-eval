========================================
Job started at: Wed Jan 28 11:39:42 PM EST 2026
Job ID: 504849
========================================
Running change_dosage perturbation for fine level...
========================================
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Random seed set to: 42
Using model: Qwen3-8B (provider: qwen)
Running single perturbation: change_dosage

================================================================================
PROCESSING LEVEL: FINE
================================================================================
Using data: /home/fb265/m3-eval/data/fine_5pt_expert+llm_consolidated.jsonl
Loaded 1229 examples
Found 250 entries in original fine ratings file
Filtering fine data to only process these 250 entries
After filtering: 250 examples to process

================================================================================
STEP 1: ORIGINAL RATINGS
================================================================================
âœ“ Loaded 250 existing original ratings from original_fine_Qwen3-8B_rating.jsonl
âœ“ All 250 original ratings complete!
âœ“ Processing 250 examples with original ratings

================================================================================
STEP 2: PERTURBATIONS
================================================================================

================================================================================
Processing perturbation: CHANGE_DOSAGE
================================================================================
Processing 250 remaining QA pairs (out of 250 total)
Saving results to: change_dosage/change_dosage_fine_Qwen3-8B_rating.jsonl
âœ“ Loaded 20 existing perturbations from change_dosage_fine.jsonl
âš  230 perturbations missing (out of 250 total)
  Generating missing perturbations...
âœ“ Generated 230 missing perturbations. Total: 20
Skipping gpt4_6_0 - no perturbation found
Skipping llama_6_2 - no perturbation found
Skipping physician_6_0 - no perturbation found
Skipping gpt4_99_4 - no perturbation found
Skipping physician_99_1 - no perturbation found
Skipping gpt4_73_3 - no perturbation found
Skipping llama_73_5 - no perturbation found
Skipping physician_73_0 - no perturbation found
Skipping gpt4_76_1 - no perturbation found
Skipping llama_76_5 - no perturbation found
Skipping physician_76_2 - no perturbation found
Skipping gpt4_77_2 - no perturbation found
Skipping llama_77_2 - no perturbation found
Skipping physician_77_0 - no perturbation found
Skipping gpt4_22_2 - no perturbation found
Skipping llama_22_0 - no perturbation found
Skipping physician_22_1 - no perturbation found
Skipping gpt4_5_0 - no perturbation found
Skipping physician_5_1 - no perturbation found
Skipping gpt4_58_0 - no perturbation found
Skipping llama_58_4 - no perturbation found
Skipping gpt4_26_5 - no perturbation found
Skipping llama_26_5 - no perturbation found
Skipping physician_26_3 - no perturbation found
Skipping physician_13_2 - no perturbation found
Skipping gpt4_47_2 - no perturbation found
Skipping physician_47_2 - no perturbation found
Skipping physician_17_3 - no perturbation found
Skipping gpt4_44_4 - no perturbation found
Skipping physician_44_1 - no perturbation found
Skipping gpt4_46_2 - no perturbation found
Skipping llama_46_3 - no perturbation found
Skipping physician_46_1 - no perturbation found
Skipping gpt4_21_1 - no perturbation found
Skipping physician_21_1 - no perturbation found
Skipping gpt4_24_0 - no perturbation found
Skipping llama_24_5 - no perturbation found
Skipping physician_24_0 - no perturbation found
Skipping gpt4_53_1 - no perturbation found
Skipping physician_53_0 - no perturbation found
Collecting 5 ratings to average...
  Run 1/5...
    Generating response (attempt 1/3)...
Loading Qwen model: Qwen3-8B... This may take a few minutes on first run.
Using CUDA (GPU: NVIDIA RTX A6000)
Using unsloth for optimized inference with 4-bit quantization...
==((====))==  Unsloth 2026.1.4: Fast Qwen3 patching. Transformers: 4.57.6.
   \\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.413 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.10.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.6.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.34. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Model loaded successfully with unsloth (4-bit)!

    Response received, validating...
  Run 2/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 3/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 4/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 5/5...
    Generating response (attempt 1/3)...
    Response received, validating...
Time taken for gpt4_7_2: 224.65 seconds
Collecting 5 ratings to average...
  Run 1/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 2/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 3/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 4/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 5/5...
    Generating response (attempt 1/3)...
    Response received, validating...
Time taken for llama_7_0: 200.82 seconds
Skipping gpt4_85_0 - no perturbation found
Skipping llama_85_3 - no perturbation found
Skipping physician_85_1 - no perturbation found
Skipping gpt4_51_3 - no perturbation found
Collecting 5 ratings to average...
  Run 1/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 2/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 3/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 4/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 5/5...
    Generating response (attempt 1/3)...
    Response received, validating...
Time taken for llama_51_5: 189.39 seconds
Collecting 5 ratings to average...
  Run 1/5...
    Generating response (attempt 1/3)...
    Response received, validating...
  Run 2/5...
    Generating response (attempt 1/3)...
